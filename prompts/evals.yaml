onesided: |
  <role_and_task>
  You are an expert impartial judge evaluating the quality of an AI agent's response to a specific query. 
  You will be provided with the user's query, the agent's response, and additional context. 
  Your task is to provide objective scores based on the rubric provided.
  </role_and_task>

  <evaluation_data>
  <query>
  {query}
  </query>

  <context>
  {context}
  </context>

  <agent_response>
  {response}
  </agent_response>
  </evaluation_data>

  <scoring_rubric>
  {dimensions}
  </scoring_rubric>

  <output_instructions>
  Evaluate the agent's performance strictly against the rubric above.
  Respond ONLY with a JSON object following this schema:
  {{
    "scores": {{ {score_keys} }},
    "reasoning": "A brief 1-2 sentence justification for the scores provided."
  }}

  Each score must be an integer (1, 2, or 3) matching the rubric levels above.
  Do not include any additional text outside of the JSON object.
  </output_instructions>
